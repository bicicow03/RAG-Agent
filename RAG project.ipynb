{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8ea687-2102-4ed1-ab20-fdf5ff3459c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the import\n",
    "import gradio as gr\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, Union, Optional, Any\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List, Union\n",
    "from operator import itemgetter\n",
    "from copy import deepcopy\n",
    "from langchain.schema.runnable import RunnableBranch, RunnablePassthrough, RunnableMap\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from functools import partial\n",
    "from langchain_community.document_loaders import NotionDirectoryLoader, NotionDBLoader\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from IPython.display import clear_output\n",
    "import datetime\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3328320-b88a-4d63-aa55-2ccc6114fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:212: UserWarning: Found mistralai/mistral-small-24b-instruct in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedder = NVIDIAEmbeddings(\n",
    "  model=\"nvidia/nv-embedqa-mistral-7b-v2\", \n",
    "  api_key=\"Enter API_KEY", \n",
    "  truncate=\"NONE\", \n",
    "  )\n",
    "\n",
    "intruct_model = ChatNVIDIA(\n",
    "  model=\"mistralai/mistral-small-24b-instruct\",\n",
    "  api_key=\"Enter API_KEY", \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "\n",
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.3-70b-instruct\",\n",
    "  api_key=\"Enter API_KEY", \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd72840-798a-4906-b7ce-5d41a98badec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_return(x, preface=\"\"):\n",
    "    print(f\"{preface}{x}\")\n",
    "    return x\n",
    "def RPrint(preface=\"\"):\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def PPrint(preface=\"State: \"):\n",
    "    def print_and_return(x, preface=\"\"):\n",
    "        print(preface, x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bb3318-fcea-4103-87d9-e8e4d679e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDBLoader(\n",
    "    integration_token=\"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\",\n",
    "    database_id=\"192dbce6201c80e490b9df38dd0af15c\",\n",
    "    request_timeout_sec=30,  # optional, defaults to 10\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "class DatabaseSummary(BaseModel):\n",
    "    task_summary: str = Field(\"\", description=\"Summary of the page_content for all tasks.\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "def include_doc(doc):\n",
    "     ## Some chunks will be overburdened with useless numerical data, so we'll filter it out\n",
    "     string = doc.page_content\n",
    "     if len([l for l in string if l.isalpha()]) < (len(string)//2):\n",
    "         return False\n",
    "     return True\n",
    "    \n",
    "## Some nice custom preprocessing\n",
    "docs_split = text_splitter.split_documents(docs)\n",
    "docs_split = [doc for doc in docs_split if include_doc(doc)]\n",
    "convstore = FAISS.from_documents(docs_split, embedding=embedder)\n",
    "retriever = convstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18a6d01-46d8-4155-9653-f7ee39d28705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5836\\3849311269.py:23: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  .replace(\"\\]\", \"]\")\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5836\\3849311269.py:24: SyntaxWarning: invalid escape sequence '\\['\n",
      "  .replace(\"\\[\", \"[\")\n"
     ]
    }
   ],
   "source": [
    "summary_promt = ChatPromptTemplate.from_template(\n",
    "    \"You are generating a list of a runnable summary for the task of the databse. Make it readable by a technical user.\"\n",
    "    \" Keep it short, but as dense and useful as possible!\"\n",
    "    \" Keep all of the information from page_summary here: {task_summary}.\"\n",
    "    \"\\n\\n{format_instructions}. Follow the format precisely, including quotations and commas\"\n",
    "    \"\\n\\nWithout losing any of the info, update the task_summary with the following: {input}\"\n",
    "    \"Make sure to summarise the current task_summary with the new input summary to ensure its not too long\"\n",
    ")\n",
    "\n",
    "def RExtract(pydantic_class, llm, prompt):\n",
    "    '''\n",
    "    Runnable Extraction module\n",
    "    Returns a knowledge dictionary populated by slot-filling extraction\n",
    "    '''\n",
    "    parser = PydanticOutputParser(pydantic_object=pydantic_class)\n",
    "    instruct_merge = RunnableAssign({'format_instructions' : lambda x: parser.get_format_instructions()})\n",
    "    def preparse(string):\n",
    "        if '{' not in string: string = '{' + string\n",
    "        if '}' not in string: string = string + '}'\n",
    "        string = (string\n",
    "            .replace(\"\\\\_\", \"_\")\n",
    "            .replace(\"\\n\", \" \")\n",
    "            .replace(\"\\]\", \"]\")\n",
    "            .replace(\"\\[\", \"[\")\n",
    "            .replace(\"  \", \"\")\n",
    "        )\n",
    "        return string\n",
    "    return instruct_merge | prompt | llm | preparse | parser\n",
    "\n",
    "def RSummarizer(knowledge, llm, prompt, verbose=False):\n",
    "\n",
    "    def summarize_docs(docs):        \n",
    "        parse_chain = RunnableAssign({'task_summary' : RExtract(knowledge.__class__, llm, prompt)})\n",
    "        \n",
    "        state = {'task_summary' : knowledge}\n",
    "        for i, doc in enumerate(docs):\n",
    "\n",
    "            state['input'] = doc.page_content\n",
    "            state = parse_chain.invoke(state)\n",
    "            assert 'task_summary' in state\n",
    "            knowledge.task_summary = state['task_summary']\n",
    "        return knowledge\n",
    "    return RunnableLambda(summarize_docs)\n",
    "\n",
    "def create_summary(doc_name):\n",
    "    relevant_docs = retriever.invoke(\"Find all documents relating to {doc_name}\")\n",
    "    database_summary = DatabaseSummary()\n",
    "    instruct_llm = intruct_model | StrOutputParser()\n",
    "    summarizer = RSummarizer(database_summary, instruct_llm, summary_promt, verbose=True)\n",
    "    summary = summarizer.invoke(relevant_docs)\n",
    "    return database_summary.task_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c738e9d-cf77-4ff4-903e-0e30b3e8fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define retriever function\n",
    "def retrieve_doc(doc_name: str):\n",
    "    relevant_doc = retriever.invoke(doc_name)\n",
    "    if not relevant_doc or not isinstance(relevant_doc, list) or len(relevant_doc) == 0:\n",
    "        raise ValueError(f\"Error: No document found with the name '{doc_name}'.\")\n",
    "    \n",
    "    database_knowledge = create_summary(doc_name)\n",
    "    \n",
    "    return {\n",
    "        \"relevant_doc\": relevant_doc[0] if isinstance(relevant_doc, list) else relevant_doc,\n",
    "        \"database_knowledge\": database_knowledge.task_summary,\n",
    "        \"input\": doc_name\n",
    "    }\n",
    "\n",
    "retriever_chain = RunnableLambda(lambda x: retrieve_doc(x[\"input\"]) if isinstance(x, dict) and \"input\" in x else retrieve_doc(x))\n",
    "\n",
    "# Extract metadata and context\n",
    "def extract_all_info(data):\n",
    "    relevant_doc = data[\"relevant_doc\"]\n",
    "    \n",
    "    if not isinstance(relevant_doc, list):\n",
    "        relevant_doc = [relevant_doc]\n",
    "    \n",
    "    meta_data = relevant_doc[0].metadata if relevant_doc else {}\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in relevant_doc) if relevant_doc else \"\"\n",
    "    current_time = datetime.datetime.now().isoformat()\n",
    "    \n",
    "    return {\n",
    "        \"meta_data\": meta_data,\n",
    "        \"context\": context,\n",
    "        \"database_knowledge\": data[\"database_knowledge\"],\n",
    "        \"current_time\": current_time,\n",
    "        \"input\": data[\"input\"]\n",
    "    }\n",
    "\n",
    "extract_chain = RunnableLambda(lambda x: extract_all_info(x))\n",
    "\n",
    "\n",
    "#Retrive only info about one specific document\n",
    "def one_doc(query: str):\n",
    "    relevant_doc = retriever.invoke(query)\n",
    "    if not relevant_doc or not isinstance(relevant_doc, list) or len(relevant_doc) == 0:\n",
    "        raise ValueError(f\"Error: No document found from the query '{query}'.\")\n",
    "\n",
    "    return {\n",
    "        \"relevant_doc\": relevant_doc,\n",
    "        \"input\": query\n",
    "    }\n",
    "\n",
    "doc_chain = RunnableLambda(lambda x: one_doc(x[\"input\"]) if isinstance(x, dict) and \"input\" in x else one_doc(x))\n",
    "\n",
    "# Extract metadata and context\n",
    "def extract_info(data):\n",
    "    relevant_doc = data[\"relevant_doc\"]\n",
    "    \n",
    "    if not isinstance(relevant_doc, list):\n",
    "        relevant_doc = [relevant_doc]\n",
    "    \n",
    "    meta_data = [doc.metadata for doc in relevant_doc]\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in relevant_doc) if relevant_doc else \"\"\n",
    "    current_time = datetime.datetime.now().isoformat()\n",
    "    \n",
    "    return {\n",
    "        \"meta_data\": meta_data,\n",
    "        \"context\": context,\n",
    "        \"input\": data[\"input\"]\n",
    "    }\n",
    "\n",
    "info_chain = RunnableLambda(lambda x: extract_info(x))\n",
    "\n",
    "\n",
    "\n",
    "# Define templates\n",
    "planning_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\",\n",
    "     \"Help complete the task and plan out the task by following the below prompt. \"\n",
    "     \"Find the due date of the document in {meta_data} by looking at its metadata. \"\n",
    "     \"Use the current date {current_time} to formulate a plan to complete the task in {context} before the due date. \"\n",
    "     \"You need to set concrete dates for when you want each part of the task done (e.g., complete the first part by 26/02/2025). \"\n",
    "     \"Also, specify the content and research needed to complete the task. \"\n",
    "     \"Also fill out and help with the plan using the knowledge you already have from {database_knowledge}.\"\n",
    "     \"Don't repeat yourself in the your planning, be concise and informative as possible\"\n",
    "     \"Just detail out the plan, don't say here's your answer or unnecessary infromation at the start\")\n",
    "])\n",
    "\n",
    "document_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"human\",\n",
    "     \"Make sure you only use information of documents with the 'task names' that are the same as one in {input}\"\n",
    "     \"The due date can sometimes be mistaken as the start date in meta data so you can treat the start date as the due date\"\n",
    "     \"Answer the question {input} relating to a specific document by using either {meta_data} or {context} or both.\"\n",
    "     \"Make sure to give all relevant information in {context} if user is asking for the content inside a docuemnt or task\"\n",
    "     \"Make sure the {meta_data} is of the correct document from input\"\n",
    "     )\n",
    "])\n",
    "\n",
    "# general_template = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful assistant\"),\n",
    "#     (\"human\",\n",
    "#      \"Say this is the general branch first and then\"\n",
    "#      \"Answer the question from {input} relating to our database by accessing {relevant_doc}.\")\n",
    "# ])\n",
    "\n",
    "classifier_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant for the DataScience Student Society\"),\n",
    "    (\"human\", \"Classify whether the user is asking for advice in planning an event/task or information about a specific document from {input}. \"\n",
    "              \"Use the specific document template when user is asking meta data information about a specific task such as the due date, status update, etc.\"\n",
    "              \"Use the plannig advice branch when user is asking help to plan or complete a task\")\n",
    "])\n",
    "\n",
    "\n",
    "# Define branches\n",
    "branches = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"planning advice\" in x[\"input\"],\n",
    "        retriever_chain | extract_chain | planning_template | intruct_model | StrOutputParser()\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"specific document\" in x[\"input\"],\n",
    "        doc_chain | info_chain | document_template | intruct_model | StrOutputParser()\n",
    "    ),\n",
    "    # (\n",
    "    #     lambda x: \"general\" in x[\"input\"].lower(),\n",
    "    #     retriever_chain | general_template | intruct_model | StrOutputParser()\n",
    "    # ),\n",
    "    RunnableLambda(lambda _: \"Sorry, I couldn't classify your request. Please clarify.\")\n",
    ")\n",
    "\n",
    "# Classification chain\n",
    "classification_chain = classifier_template | client | StrOutputParser() | RunnableLambda(lambda x: {\"input\": x})\n",
    "\n",
    "# Full RAG pipeline\n",
    "chain = classification_chain | branches\n",
    "\n",
    "def generate_chat(user_input):\n",
    "    try:\n",
    "        return chain.invoke({\"input\": user_input})\n",
    "    except ValueError as e:\n",
    "        return str(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889e1b9c-dac0-47a0-a382-73aa287ae32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ“… AI Assistant\")\n",
    "    doc_input = gr.Textbox(label=\"Enter Query\")\n",
    "    output = gr.Textbox(label=\"Response\", interactive=False)\n",
    "    submit_btn = gr.Button(\"Generate Response\")\n",
    "    \n",
    "    submit_btn.click(generate_chat, inputs=doc_input, outputs=output)\n",
    "\n",
    "# Launch Gradio App\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
