{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e94d06b0-25ff-46bb-b660-bac778ec7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tensorflow\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#All the import\n",
    "import gradio as gr\n",
    "import datetime\n",
    "import uuid\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import NotionDirectoryLoader, NotionDBLoader\n",
    "from pydantic import BaseModel\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import tools_condition, ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e068362-8037-448a-b7dd-4db61dfdc351",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = NVIDIAEmbeddings(\n",
    "  model=\"nvidia/nv-embedqa-mistral-7b-v2\", \n",
    "  api_key=\"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\", \n",
    "  truncate=\"NONE\", \n",
    "  )\n",
    "\n",
    "# intruct_model = ChatNVIDIA(\n",
    "#   model=\"mistralai/mistral-small-24b-instruct\",\n",
    "#   api_key=\"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\", \n",
    "#   temperature=0.2,\n",
    "#   top_p=0.7,\n",
    "#   max_tokens=1024,\n",
    "# )\n",
    "\n",
    "\n",
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.3-70b-instruct\",\n",
    "  api_key=\"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\", \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "# client = ChatNVIDIA(\n",
    "#   model=\"meta/llama-3.1-8b-instruct\",\n",
    "#   api_key=\"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\", \n",
    "#   temperature=0.2,\n",
    "#   top_p=0.7,\n",
    "#   max_tokens=1024,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affe88d1-80e2-43aa-927e-a4f4f5204baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDBLoader(\n",
    "    integration_token=\"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\",\n",
    "    database_id=\"192dbce6201c80e490b9df38dd0af15c\",\n",
    "    request_timeout_sec=30,  # optional, defaults to 10\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "def include_doc(doc):\n",
    "     ## Some chunks will be overburdened with useless numerical data, so we'll filter it out\n",
    "     string = doc.page_content\n",
    "     if len([l for l in string if l.isalpha()]) < (len(string)//2):\n",
    "         return False\n",
    "     return True\n",
    "    \n",
    "## Some nice custom preprocessing\n",
    "docs_split = text_splitter.split_documents(docs)\n",
    "docs_split = [doc for doc in docs_split if include_doc(doc)]\n",
    "convstore = FAISS.from_documents(docs_split, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf189f38-88b0-401a-9d0c-1139bcc3aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from this block is created by Gemini, doesn't work, prob cuz we only using database and not a page type so dont hav real Page ID to modify database content.\n",
    "from notion_client import Client\n",
    "import os\n",
    "\n",
    "# --- Initialization ---\n",
    "# It's better practice to load secrets from environment variables\n",
    "# For example: notion_token = os.getenv(\"NOTION_TOKEN\")\n",
    "# Using the provided token directly for this example:\n",
    "notion_token = \"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\"\n",
    "if not notion_token:\n",
    "    raise ValueError(\"Notion API token not found. Set NOTION_TOKEN environment variable or add it directly.\")\n",
    "\n",
    "notion = Client(auth=notion_token)\n",
    "# Your specific Notion Database ID\n",
    "database_id = \"192dbce6201c80e490b9df38dd0af15c\"\n",
    "\n",
    "def update_task_status(task_name: str, new_status: str) -> str:\n",
    "    \"\"\"\n",
    "    Updates the status of a task in the specified Notion database by its exact name.\n",
    "\n",
    "    Args:\n",
    "        task_name: The exact name of the task (title property) to update.\n",
    "        new_status: The new status value (must be a valid option in Notion).\n",
    "\n",
    "    Returns:\n",
    "        A string indicating success or failure, including potential error details.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    # !! IMPORTANT !!: Verify these property names match your Notion database exactly.\n",
    "    title_property_name = \"Task Names\" # The name of your \"Title\" property column\n",
    "    status_property_name = \"Status Update\" # The name of your \"Status\" property column\n",
    "\n",
    "    try:\n",
    "        # 1. Query for the page using the exact task name in the title property\n",
    "        query_filter = {\n",
    "            \"property\": title_property_name,\n",
    "            \"title\": {\"equals\": task_name}\n",
    "        }\n",
    "        results = notion.databases.query(\n",
    "            database_id=database_id,\n",
    "            filter=query_filter,\n",
    "        )\n",
    "\n",
    "        # Check if any results were found\n",
    "        if not results or not results.get(\"results\"):\n",
    "            # You could add a fallback search using \"contains\" here if desired\n",
    "            return f\"Error: No task found with the exact name: '{task_name}' in property '{title_property_name}'.\"\n",
    "\n",
    "        # Handle cases where the exact name matches multiple pages (should be rare for titles)\n",
    "        if len(results[\"results\"]) > 1:\n",
    "             return f\"Error: Multiple tasks found with the exact name '{task_name}'. Please ensure task names are unique.\"\n",
    "\n",
    "        # 2. Get the Page ID from the (first and only) query result\n",
    "        page_id_to_update = results[\"results\"][0][\"id\"]\n",
    "\n",
    "        # 3. Prepare the properties payload for the update\n",
    "        properties_to_update = {\n",
    "            status_property_name: {\n",
    "                \"status\": {\n",
    "                    \"name\": new_status # This name MUST match a valid status option in Notion\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 4. Execute the page update\n",
    "        notion.pages.update(\n",
    "            page_id=page_id_to_update, # Use the dynamically found page_id\n",
    "            properties=properties_to_update\n",
    "        )\n",
    "\n",
    "        return f\"Success: Task '{task_name}' (Page ID: {page_id_to_update}) status updated to '{new_status}' in property '{status_property_name}'.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch potential API errors and provide informative feedback\n",
    "        error_message = str(e)\n",
    "        print(f\"Notion API Error attempting to update task '{task_name}' to status '{new_status}': {error_message}\")\n",
    "\n",
    "        # Try to give more specific feedback based on common Notion API errors\n",
    "        if \"validation failed\" in error_message.lower() or \"is not a valid option\" in error_message.lower():\n",
    "             return f\"Failed to update task '{task_name}'. Error: '{new_status}' is likely an invalid status option for the '{status_property_name}' property in Notion. Please use a valid status name.\"\n",
    "        elif \"could not find page\" in error_message.lower():\n",
    "             # This might happen if the page was deleted between query and update\n",
    "             return f\"Failed to update task '{task_name}'. Error: Could not find the page (ID: {page_id_to_update}) just before updating. It might have been deleted.\"\n",
    "        elif \"permission\" in error_message.lower():\n",
    "             return f\"Failed to update task '{task_name}'. Error: The Notion integration token lacks permission to edit pages in database ID '{database_id}'.\"\n",
    "        else:\n",
    "             # General error catch-all\n",
    "             return f\"Failed to update task '{task_name}'. An unexpected Notion API error occurred: {error_message}\"\n",
    "\n",
    "# --- Tool Binding Example (ensure 'client' is your LLM instance) ---\n",
    "# Assuming 'client' is your ChatNVIDIA or similar LangChain LLM client instance\n",
    "tools = [update_task_status]\n",
    "client_tools = client.bind_tools(tools)\n",
    "\n",
    "# --- Direct Call Example (for testing) ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Replace with a real task name from your DB and a VALID status option\n",
    "#     test_task = \"Information on Machine Learning\"\n",
    "#     valid_status = \"In Progress\"\n",
    "#     invalid_status = \"Totally Finished\" # Assume this is NOT a valid option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbec773-4cdd-4533-b378-9996d4b91cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         +-----------+           \n",
      "         | __start__ |           \n",
      "         +-----------+           \n",
      "          ..        ..           \n",
      "        ..            ..         \n",
      "       .                .        \n",
      "+--------+          +----------+ \n",
      "| Normal |          | Notiondb | \n",
      "+--------+        ..+----------+ \n",
      "      *       ....        *      \n",
      "      *    ...            *      \n",
      "      *  ..               *      \n",
      "+---------+          +-------+   \n",
      "| __end__ |          | tools |   \n",
      "+---------+          +-------+   \n"
     ]
    }
   ],
   "source": [
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "def Normal(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier. While u cannot confirm any of the AI responses, assume that they are all correct {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "    response = client.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": response\n",
    "    }\n",
    "\n",
    "def Notiondb(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "        \n",
    "    formating = \"\"\"\n",
    "    You be given a information on a few documents relating to the user query.\n",
    "    If user is asking information about one specific document then only give them information on that one document only. Do\n",
    "    not use other documents information\n",
    "    If the user is asking information about a collection of doucments then you can decide which documents user is asking for and\n",
    "    use multiple documents to answer the query\n",
    "    Be concise and get to the point with your answer. Then ask user if there's anything else they need\n",
    "    You can also update the Notion Database\n",
    "    \"\"\"\n",
    "\n",
    "    current_time = datetime.datetime.now().isoformat()\n",
    "    relevant_doc = retriever.invoke(state[\"messages\"][-1].content)\n",
    "    data = [info.metadata for info in relevant_doc]\n",
    "    all_metadata = [doc.metadata for doc in docs]\n",
    "    context = \"\\n\\n\".join(\n",
    "    f\"This part belongs to the document {doc.metadata['task names']}\\n\\n{doc.page_content}\"\n",
    "    for doc in relevant_doc\n",
    "    )\n",
    "    query = str(current_time) + str(all_metadata) + context + \"Answer the questions using information provided\" + formating\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=query)]\n",
    "    answer = client_tools.invoke(messages)\n",
    "    return  {\n",
    "        \"messages\": answer\n",
    "    }\n",
    "\n",
    "def DecideFunction(state: State):\n",
    "    instruction =\"\"\"\n",
    "    Determine if user is asking/talking about general stuff or information relating to the task/documents in Notion Database. \n",
    "    You have been given a list of all the document's name from the database.\n",
    "    Answer in 0 if the document or task the user is asking about is in the documents list or they mention the notion database specifically\n",
    "    Only answer in 1 if the user is just making conversation.\n",
    "    Make sure u only return the number either 0 or 1.\n",
    "    \"\"\"\n",
    "\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    all_documents = [doc.metadata[\"task names\"] for doc in docs]\n",
    "    query = last_message + \"Document names:\" + str(all_documents) + instruction\n",
    "    decision = client.invoke(query)\n",
    "    \n",
    "    if decision.content == \"0\":\n",
    "        return \"Notiondb\"\n",
    "    return \"Normal\"\n",
    "\n",
    "#Function copied from LangGraph course\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"\"\"\n",
    "            You are a chatbot and have been conversing with the user.\n",
    "            Now extend the summary by taking into account the new messages above\n",
    "            Do not worry about the information accuracy or anything.\n",
    "            While u cannot confirm any of the AI responses, assume that they are all correct and include them in the summerisation\n",
    "            Your job is to literally summerise the conversation and nothing else\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"\"\"\n",
    "        You are a chatbot and have been conversing with the user.\n",
    "        Now create a summary of the conversation, do not worry about the information accuracy or anything.\n",
    "        While u cannot confirm any of the AI responses, assume that they are all correct and include them in the summerisation\n",
    "        Your job is to literally summerise the conversation and nothing else.\"\"\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = client.invoke(messages)\n",
    "    print(response)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Function copied from LangGraph course\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"Normal\", Normal)\n",
    "builder.add_node(\"Notiondb\", Notiondb)\n",
    "builder.add_node(summarize_conversation)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_conditional_edges(START, DecideFunction, [\"Normal\", \"Notiondb\"])\n",
    "builder.add_conditional_edges(\"Normal\", should_continue)\n",
    "builder.add_conditional_edges(\"Notiondb\", should_continue)\n",
    "builder.add_conditional_edges(\"Notiondb\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"Notiondb\")\n",
    "builder.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Add\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "graph.get_graph().print_ascii()\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497230b1-eb5b-4511-b113-0394103c8fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yo, what's up pookie\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Not much, just hanging out in the digital realm! It's great to chat with you, though! What's on your mind? Want to talk about something in particular or just shoot the breeze?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Yo, what's up pookie\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa34e41d-31a3-4deb-b7d2-1824d617cfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yo, what's up pookie\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Not much, just hanging out in the digital realm! It's great to chat with you, though! What's on your mind? Want to talk about something in particular or just shoot the breeze?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the due date of the Information on Machine Learning task?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The due date of the \"Information on Machine Learning\" task is 2025-06-18. \n",
      "\n",
      "Is there anything else you need?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"What's the due date of the Information on Machine Learning task?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed1c3a2-4ab3-4593-af23-d4056616b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yo, what's up pookie\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Not much, just hanging out in the digital realm! It's great to chat with you, though! What's on your mind? Want to talk about something in particular or just shoot the breeze?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the due date of the Information on Machine Learning task?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The due date of the \"Information on Machine Learning\" task is 2025-06-18. \n",
      "\n",
      "Is there anything else you need?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yea can u remind me of the content inside the Business of Music document?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The content inside the Business of Music document includes an introduction to the ethics and economic impact of AI in music production, a history of the recording music industry, and the evolution of techniques and tools used by businesses to connect creators with consumers. It also discusses the challenges faced by the industry with the creation and usage of AI songwriting tools, copyright laws, and the economic and ethical implications for music creators.\n",
      "\n",
      "Is there anything else you need?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"Yea can u remind me of the content inside the Business of Music document?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19715ed-65da-4aff-b4af-03f77f99b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The conversation started with a casual greeting. The user then asked about the due date of the \"Information on Machine Learning\" task, which was stated to be 2025-06-18. The user also inquired about the content of the \"Business of Music\" document, which was said to include topics such as the ethics and economic impact of AI in music production, the history of the recording music industry, and the evolution of techniques and tools used by businesses. Additionally, the user asked about tasks assigned to \"bike\" in the Notion Database, which included tasks like \"Cyber report\", \"ML Workshop\", \"Game Design\", \"NNO CUP RULES\", and \"Information on Machine Learning\" with their respective due dates.' additional_kwargs={} response_metadata={'role': 'assistant', 'content': 'The conversation started with a casual greeting. The user then asked about the due date of the \"Information on Machine Learning\" task, which was stated to be 2025-06-18. The user also inquired about the content of the \"Business of Music\" document, which was said to include topics such as the ethics and economic impact of AI in music production, the history of the recording music industry, and the evolution of techniques and tools used by businesses. Additionally, the user asked about tasks assigned to \"bike\" in the Notion Database, which included tasks like \"Cyber report\", \"ML Workshop\", \"Game Design\", \"NNO CUP RULES\", and \"Information on Machine Learning\" with their respective due dates.', 'token_usage': {'prompt_tokens': 436, 'total_tokens': 586, 'completion_tokens': 150}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'} id='run-23594dc4-ff0b-4cf3-a770-a3e9058e0cc4-0' usage_metadata={'input_tokens': 436, 'output_tokens': 150, 'total_tokens': 586} role='assistant'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can u tell me all task assigned to bike in the Notion Database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The tasks assigned to \"bike\" in the Notion Database are:\n",
      "\n",
      "1. Cyber report (due date: 2025-09-22)\n",
      "2. ML Workshop (due date: 2025-05-09)\n",
      "3. Game Design (due date: 2025-05-18)\n",
      "4. NNO CUP RULES (due date: 2025-08-20)\n",
      "5. Information on Machine Learning (due date: 2025-06-18)\n",
      "\n",
      "Is there anything else you need?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"Can u tell me all task assigned to bike in the Notion Database?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92d56b9-755d-450e-83d1-cb8a1bf6ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can u tell me all task assigned to bike in the Notion Database?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The tasks assigned to \"bike\" in the Notion Database are:\n",
      "\n",
      "1. Cyber report (due date: 2025-09-22)\n",
      "2. ML Workshop (due date: 2025-05-09)\n",
      "3. Game Design (due date: 2025-05-18)\n",
      "4. NNO CUP RULES (due date: 2025-08-20)\n",
      "5. Information on Machine Learning (due date: 2025-06-18)\n",
      "\n",
      "Is there anything else you need?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you give me all status updates of all task in the Notion Database\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't have have access to a Notion Database, and I didn't receive any information about the tasks or their status updates. My previous response was an error.\n",
      "\n",
      "If you'd like to share the information about the tasks and their status updates, I'd be happy to help you organize or discuss them. Alternatively, if you have a specific Notion Database and would like to share the link or the information, I can try to assist you with that.\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"Can you give me all status updates of all task in the Notion Database\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84852bb4-4bcb-4594-9b6a-9477413fd598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Here is a summary of the conversation to date:\\n\\nThe conversation started with a casual greeting. The user then asked about tasks assigned to \"bike\" in the Notion Database, and was informed that the tasks included \"Cyber report\", \"ML Workshop\", \"Game Design\", \"NNO CUP RULES\", and \"Information on Machine Learning\" with their respective due dates. The user then asked for all status updates of all tasks in the Notion Database, but no information was provided. The user then asked to mark the \"Business of Music\" document task as done, and was informed that the task status was updated to \"Done\". The user also inquired about the content of the \"Business of Music\" document, which was said to include topics such as the ethics and economic impact of AI in music production. \\n\\nNote that the initial summary provided by the user was not entirely accurate, as it mentioned the due date of the \"Information on Machine Learning\" task, which was not discussed in the conversation. However, the rest of the summary has been incorporated into this updated version.' additional_kwargs={} response_metadata={'role': 'assistant', 'content': 'Here is a summary of the conversation to date:\\n\\nThe conversation started with a casual greeting. The user then asked about tasks assigned to \"bike\" in the Notion Database, and was informed that the tasks included \"Cyber report\", \"ML Workshop\", \"Game Design\", \"NNO CUP RULES\", and \"Information on Machine Learning\" with their respective due dates. The user then asked for all status updates of all tasks in the Notion Database, but no information was provided. The user then asked to mark the \"Business of Music\" document task as done, and was informed that the task status was updated to \"Done\". The user also inquired about the content of the \"Business of Music\" document, which was said to include topics such as the ethics and economic impact of AI in music production. \\n\\nNote that the initial summary provided by the user was not entirely accurate, as it mentioned the due date of the \"Information on Machine Learning\" task, which was not discussed in the conversation. However, the rest of the summary has been incorporated into this updated version.', 'token_usage': {'prompt_tokens': 733, 'total_tokens': 952, 'completion_tokens': 219}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'} id='run-adfdfe68-af5e-4a20-afaa-ae6d8cf13a30-0' usage_metadata={'input_tokens': 733, 'output_tokens': 219, 'total_tokens': 952} role='assistant'\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_task_status\n",
      "\n",
      "Success: Task 'Business of Music' (Page ID: 19cdbce6-201c-80c3-a97c-e518268fc67d) status updated to 'Done' in property 'Status Update'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The document \"Business of Music\" has the following information:\n",
      "\n",
      "The ethics and economic impact surrounding the Integration of AI in music production and creativity in the recorded music industry. The music industry has consistently needed to adapt to new technologies and implement new ways in which music is produced, consumed and marketed. The newest challenge currently faced by the industry is the creation and usage of AI song writing tools, specifically the copyright laws surrounding it and the economic and ethical implications it brings to music creators.\n",
      "\n",
      "Is there anything else you need? \n",
      "\n",
      "<function@update_task_status>{\"task_name\": \"Business of Music\", \"new_status\": \"Done\"}</function>\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"Can you mark the Business of Music document task as done\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9181bac4-f346-4117-9c95-05442f658244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a summary of the conversation to date:\\n\\nThe conversation started with a casual greeting. The user then asked about tasks assigned to \"bike\" in the Notion Database, and was informed that the tasks included \"Cyber report\", \"ML Workshop\", \"Game Design\", \"NNO CUP RULES\", and \"Information on Machine Learning\" with their respective due dates. The user then asked for all status updates of all tasks in the Notion Database, but no information was provided. The user then asked to mark the \"Business of Music\" document task as done, and was informed that the task status was updated to \"Done\". The user also inquired about the content of the \"Business of Music\" document, which was said to include topics such as the ethics and economic impact of AI in music production. \\n\\nNote that the initial summary provided by the user was not entirely accurate, as it mentioned the due date of the \"Information on Machine Learning\" task, which was not discussed in the conversation. However, the rest of the summary has been incorporated into this updated version.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23058301-ab85-45a6-829a-7ede257a5ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: update_task_status\n",
      "\n",
      "Success: Task 'Business of Music' (Page ID: 19cdbce6-201c-80c3-a97c-e518268fc67d) status updated to 'Done' in property 'Status Update'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The document \"Business of Music\" has the following information:\n",
      "\n",
      "The ethics and economic impact surrounding the Integration of AI in music production and creativity in the recorded music industry. The music industry has consistently needed to adapt to new technologies and implement new ways in which music is produced, consumed and marketed. The newest challenge currently faced by the industry is the creation and usage of AI song writing tools, specifically the copyright laws surrounding it and the economic and ethical implications it brings to music creators.\n",
      "\n",
      "Is there anything else you need? \n",
      "\n",
      "<function@update_task_status>{\"task_name\": \"Business of Music\", \"new_status\": \"Done\"}</function>\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the status update for the Business of Music task?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The status update for the Business of Music task is 'Not started'. \n",
      "\n",
      "Is there anything else you need?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"What is the status update for the Business of Music task?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525c7903-6cb9-4f36-bacc-4c7b9808141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tensorflow\\Lib\\site-packages\\gradio\\components\\chatbot.py:273: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code below was generated entirely by Gemini code for deployment phase\n",
    "# Assuming 'graph' is your compiled LangGraph with MemorySaver from previous cells\n",
    "# Assuming 'State' class is defined\n",
    "\n",
    "# --- Keep your LangGraph setup code above this ---\n",
    "\n",
    "# Corrected Gradio Interface Function\n",
    "def chat_interface(message, history, thread_id_state):\n",
    "    # Ensure a thread_id exists for the session, create if not\n",
    "    if not thread_id_state:\n",
    "        thread_id_state = \"thread_\" + str(uuid.uuid4())\n",
    "        print(f\"New session started with thread_id: {thread_id_state}\") # For debugging\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id_state}}\n",
    "\n",
    "    # Prepare the input for the graph - just the new user message\n",
    "    input_message = HumanMessage(content=message)\n",
    "    input_data = {\"messages\": [input_message]}\n",
    "\n",
    "    # Invoke the graph - MemorySaver loads history based on thread_id\n",
    "    # Pass config using the 'config' keyword argument\n",
    "    output_state = graph.invoke(input_data, config=config)\n",
    "\n",
    "    # The output_state['messages'] contains the updated full history\n",
    "    # We need the last message which should be the AI's response\n",
    "    ai_response_content = \"\"\n",
    "    if output_state and \"messages\" in output_state and output_state[\"messages\"]:\n",
    "        last_message = output_state[\"messages\"][-1]\n",
    "        if isinstance(last_message, AIMessage):\n",
    "            ai_response_content = last_message.content\n",
    "        else:\n",
    "            # Handle cases where the last message might not be AI (e.g., error, graph structure)\n",
    "            print(\"Warning: Last message was not from AI:\", last_message)\n",
    "            ai_response_content = \"Sorry, I encountered an issue processing that.\"\n",
    "\n",
    "    # Update Gradio's history (list of lists)\n",
    "    # The 'history' variable holds the previous turns [[user, ai], [user, ai]]\n",
    "    updated_gradio_history = history + [[message, ai_response_content]]\n",
    "\n",
    "    # Return the updated Gradio history and the persistent thread_id\n",
    "    return updated_gradio_history, updated_gradio_history, thread_id_state\n",
    "\n",
    "# Gradio blocks app\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## ðŸ§  LangGraph Chatbot Interface\")\n",
    "\n",
    "    # Chatbot component to display conversation\n",
    "    chatbot = gr.Chatbot(label=\"Your Assistant\")\n",
    "\n",
    "    # Textbox for user input\n",
    "    msg = gr.Textbox(label=\"Enter your message\")\n",
    "\n",
    "    # State to store Gradio's view of history (list of lists) for display\n",
    "    history_state = gr.State([])\n",
    "\n",
    "    # State to store the LangGraph thread_id across interactions for this session\n",
    "    thread_id_state = gr.State(None) # Initialize as None\n",
    "\n",
    "    # Function to clear the textbox after submission\n",
    "    def clear_textbox():\n",
    "        return gr.Textbox(value=\"\")\n",
    "\n",
    "    # Connect the submit action (when user presses Enter or clicks Submit)\n",
    "    msg.submit(\n",
    "        chat_interface,\n",
    "        # Inputs: current message, Gradio history, LangGraph thread_id\n",
    "        inputs=[msg, history_state, thread_id_state],\n",
    "        # Outputs: updated chatbot display, updated Gradio history, updated thread_id\n",
    "        outputs=[chatbot, history_state, thread_id_state]\n",
    "    ).then(\n",
    "        clear_textbox, # After chat_interface runs, clear the textbox\n",
    "        inputs=None,\n",
    "        outputs=msg\n",
    "    )\n",
    "\n",
    "\n",
    "# Launch Gradio App\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaae2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
